#!/usr/bin/env python3
"""
DevSecOps Sentinel - Vulnerability Scanner Lambda Function (Production Version)
Scans for vulnerabilities in Python and Node.js dependencies using real tools.
"""

import io
import json
import logging
import os
import subprocess
import tempfile
import zipfile
from typing import Dict, List, Any, Optional

import boto3
import requests

# Add layer bin directory to PATH for Lambda layer tools
if '/opt/bin' not in os.environ.get('PATH', ''):
    os.environ['PATH'] = '/opt/bin:' + os.environ.get('PATH', '')

from sentinel_utils.utils import (
    get_github_token,
    create_session_with_retries,
    format_error_response,
    format_success_response,
    DEFAULT_TIMEOUT
)

# Configure logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Initialize AWS clients
secrets_manager = boto3.client("secretsmanager")

# Scanner type constant
SCANNER_TYPE = "vulnerabilities"

# Tool paths to search for scanner binaries
SAFETY_PATHS = ['/opt/python/bin/safety', '/var/lang/bin/python3', 'python3']  # Use Python to run safety module
NPM_PATHS = ['/opt/bin/npm', 'npm', '/usr/bin/npm']

# File patterns
PYTHON_DEPS_FILE = 'requirements.txt'
NODE_DEPS_FILE = 'package.json'

def lambda_handler(event, context):
    """
    Main Lambda handler for vulnerability scanning.
    Downloads repository and scans dependency files for vulnerabilities.
    """
    try:
        logger.info("VulnerabilityScannerFunction invoked - REAL scanning")

        # Debug mode - check layer contents
        if event.get('debug_layer'):
            return debug_layer_contents()

        # Extract repository details
        repo_details = event.get('repo_details', {})
        repo_full_name = repo_details.get('repository_full_name', '')
        commit_sha = repo_details.get('commit_sha', '')
        pr_number = repo_details.get('pr_number')

        if not repo_full_name or not commit_sha:
            return format_error_response(SCANNER_TYPE, ValueError("Repository name and commit SHA are required"))

        logger.info(f"Scanning repository: {repo_full_name}, PR: {pr_number}")

        # Download repository and scan for dependency files
        github_token = get_github_token()
        headers = {'Authorization': f'token {github_token}'}
        zip_url = f"https://api.github.com/repos/{repo_full_name}/zipball/{commit_sha}"

        all_findings = scan_repository_dependencies(zip_url, headers)

        logger.info(f"Vulnerability scan completed. Found {len(all_findings)} total vulnerabilities.")

        return format_success_response(SCANNER_TYPE, all_findings)

    except requests.exceptions.HTTPError as e:
        logger.error(f"GitHub API HTTP error: {e.response.status_code} - {e.response.text}", exc_info=True)
        return format_error_response(
            SCANNER_TYPE,
            Exception(f"GitHub API error: {e.response.status_code}")
        )
    except Exception as e:
        logger.error(f"Error in vulnerability scanner: {e}", exc_info=True)
        return format_error_response(SCANNER_TYPE, e)

def debug_layer_contents():
    """Debug function to check what's available in the layer"""
    import subprocess

    results = {
        "paths_checked": [],
        "files_found": [],
        "environment": {},
        "tool_checks": [],
        "tool_tests": []
    }

    # Check environment variables
    results["environment"]["PATH"] = os.environ.get("PATH", "")
    results["environment"]["PYTHONPATH"] = os.environ.get("PYTHONPATH", "")

    # Check common paths
    paths_to_check = ["/opt", "/opt/bin", "/opt/python", "/var/lang/bin", "/usr/bin"]

    for path in paths_to_check:
        results["paths_checked"].append(path)
        if os.path.exists(path):
            try:
                contents = os.listdir(path)
                results["files_found"].append({"path": path, "contents": contents})
            except Exception as e:
                results["files_found"].append({"path": path, "error": str(e)})

    # Check specific tools
    tools_to_check = ["/opt/bin/safety", "/opt/bin/npm", "safety", "npm"]

    for tool in tools_to_check:
        tool_result = {"tool": tool}

        if os.path.exists(tool):
            tool_result["exists"] = True
            tool_result["executable"] = os.access(tool, os.X_OK)
        else:
            tool_result["exists"] = False

        try:
            result = subprocess.run(["which", tool], capture_output=True, text=True)
            tool_result["which_result"] = result.stdout.strip() if result.returncode == 0 else "not found"
        except Exception as e:
            tool_result["which_error"] = str(e)

        results["tool_checks"].append(tool_result)

    # Test actual tool execution
    python_cmd = '/var/lang/bin/python3'
    env = os.environ.copy()
    env['PYTHONPATH'] = '/opt/python:' + env.get('PYTHONPATH', '')

    # Test pip-audit
    try:
        cmd = [python_cmd, '-m', 'pip_audit', '--version']
        result = subprocess.run(cmd, capture_output=True, text=True, env=env, timeout=10)
        results["tool_tests"].append({
            "tool": "pip_audit",
            "command": " ".join(cmd),
            "return_code": result.returncode,
            "stdout": result.stdout[:200],
            "stderr": result.stderr[:200]
        })
    except Exception as e:
        results["tool_tests"].append({
            "tool": "pip_audit",
            "error": str(e)
        })

    # Test safety
    try:
        cmd = [python_cmd, '-m', 'safety', '--version']
        result = subprocess.run(cmd, capture_output=True, text=True, env=env, timeout=10)
        results["tool_tests"].append({
            "tool": "safety",
            "command": " ".join(cmd),
            "return_code": result.returncode,
            "stdout": result.stdout[:200],
            "stderr": result.stderr[:200]
        })
    except Exception as e:
        results["tool_tests"].append({
            "tool": "safety",
            "error": str(e)
        })

    return {
        "statusCode": 200,
        "scanner_type": "debug",
        "debug_results": results
    }

def find_tool(tool_paths: List[str]) -> Optional[str]:
    """Find the first available tool from a list of paths."""
    for tool_path in tool_paths:
        # Check if absolute path exists and is executable
        if os.path.exists(tool_path) and os.access(tool_path, os.X_OK):
            return tool_path

        # For relative paths, check in PATH
        if not tool_path.startswith('/'):
            # Check in common directories
            for path_dir in ['/opt/bin', '/usr/bin', '/bin', '/var/lang/bin']:
                full_path = os.path.join(path_dir, tool_path)
                if os.path.exists(full_path) and os.access(full_path, os.X_OK):
                    return full_path

    return None

def scan_repository_dependencies(zip_url: str, headers: Dict[str, str]) -> List[Dict[str, Any]]:
    """
    Download repository zipball and scan dependency files for vulnerabilities.

    Args:
        zip_url: GitHub API URL for repository zipball
        headers: HTTP headers including GitHub token

    Returns:
        List of vulnerability findings
    """
    all_findings = []

    with tempfile.TemporaryDirectory() as temp_dir:
        # Download repository zipball
        session = create_session_with_retries()
        response = session.get(zip_url, headers=headers, timeout=DEFAULT_TIMEOUT)
        response.raise_for_status()

        # Extract zipball
        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:
            zip_file.extractall(temp_dir)

        # Find the extracted directory (GitHub creates a directory with repo name and commit)
        extracted_dirs = [d for d in os.listdir(temp_dir) if os.path.isdir(os.path.join(temp_dir, d))]
        if not extracted_dirs:
            logger.warning("No directories found in extracted zipball")
            return all_findings

        repo_dir = os.path.join(temp_dir, extracted_dirs[0])
        logger.info(f"Scanning repository directory: {repo_dir}")

        # Find and scan dependency files
        dependency_files = find_dependency_files(repo_dir)
        logger.info(f"Found {len(dependency_files)} dependency files total")

        for file_path, file_type in dependency_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                relative_path = os.path.relpath(file_path, repo_dir)
                logger.info(f"Processing {file_type} file: {relative_path} (size: {len(content)} chars)")

                if file_type == 'python':
                    logger.info(f"Scanning Python dependencies from: {relative_path}")
                    logger.info(f"Content preview: {content[:200]}...")
                    findings = scan_python_dependencies(content, relative_path)
                    logger.info(f"Python scan found {len(findings)} vulnerabilities")
                    all_findings.extend(findings)
                elif file_type == 'nodejs':
                    logger.info(f"Scanning Node.js dependencies from: {relative_path}")
                    logger.info(f"Content preview: {content[:200]}...")
                    findings = scan_node_dependencies(content, relative_path)
                    logger.info(f"Node.js scan found {len(findings)} vulnerabilities")
                    all_findings.extend(findings)

            except Exception as e:
                logger.error(f"Error scanning {file_path}: {e}")
                continue

    return all_findings

def find_dependency_files(repo_dir: str) -> List[tuple]:
    """
    Find dependency files in the repository.

    Args:
        repo_dir: Repository directory path

    Returns:
        List of tuples (file_path, file_type)
    """
    dependency_files = []

    for root, dirs, files in os.walk(repo_dir):
        for file in files:
            file_path = os.path.join(root, file)

            if file == PYTHON_DEPS_FILE:
                dependency_files.append((file_path, 'python'))
            elif file == NODE_DEPS_FILE:
                dependency_files.append((file_path, 'nodejs'))

    return dependency_files

def scan_python_dependencies(requirements_content: str, file_path: str) -> List[Dict[str, Any]]:
    """
    Scan Python dependencies using OSV (Open Source Vulnerabilities) API.
    """
    findings = []

    if not requirements_content.strip():
        return findings

    logger.info(f"Scanning Python dependencies using OSV API")

    # Parse requirements.txt
    packages = []
    for line in requirements_content.strip().split('\n'):
        line = line.strip()
        if not line or line.startswith('#'):
            continue

        # Parse package==version format
        if '==' in line:
            package_name, version = line.split('==', 1)
            packages.append({
                'name': package_name.strip(),
                'version': version.strip()
            })

    logger.info(f"Found {len(packages)} Python packages to scan")

    # Query OSV API for each package
    session = create_session_with_retries()

    for package in packages:
        try:
            # Query OSV API
            osv_query = {
                "package": {
                    "name": package['name'],
                    "ecosystem": "PyPI"
                },
                "version": package['version']
            }

            response = session.post(
                'https://api.osv.dev/v1/query',
                json=osv_query,
                timeout=10
            )

            if response.status_code == 200:
                osv_data = response.json()
                vulns = osv_data.get('vulns', [])

                for vuln in vulns:
                    finding = {
                        "type": "vulnerability",
                        "language": "python",
                        "package": package['name'],
                        "version": package['version'],
                        "severity": "HIGH",  # OSV doesn't always provide severity
                        "description": vuln.get('summary', 'Vulnerability found'),
                        "vulnerability_id": vuln.get('id', 'UNKNOWN'),
                        "file": file_path
                    }
                    findings.append(finding)
                    logger.info(f"Found vulnerability: {package['name']} {package['version']} - {vuln.get('id')}")

        except Exception as e:
            logger.error(f"Error querying OSV for {package['name']}: {e}")
            continue

    logger.info(f"OSV scan found {len(findings)} Python vulnerabilities")
    return findings

def scan_node_dependencies(package_json_content: str, file_path: str) -> List[Dict[str, Any]]:
    """
    Scan Node.js dependencies using OSV (Open Source Vulnerabilities) API.
    """
    findings = []

    if not package_json_content.strip():
        return findings

    logger.info(f"Scanning Node.js dependencies using OSV API")

    try:
        # Parse package.json
        package_data = json.loads(package_json_content)

        # Get all dependencies
        packages = []
        all_deps = {}
        all_deps.update(package_data.get('dependencies', {}))
        all_deps.update(package_data.get('devDependencies', {}))

        for package_name, version in all_deps.items():
            # Clean version (remove ^ ~ etc.)
            clean_version = version.lstrip('^~>=<')
            packages.append({
                'name': package_name,
                'version': clean_version
            })

        logger.info(f"Found {len(packages)} Node.js packages to scan")

        # Query OSV API for each package
        session = create_session_with_retries()

        for package in packages:
            try:
                # Query OSV API
                osv_query = {
                    "package": {
                        "name": package['name'],
                        "ecosystem": "npm"
                    },
                    "version": package['version']
                }

                response = session.post(
                    'https://api.osv.dev/v1/query',
                    json=osv_query,
                    timeout=10
                )

                if response.status_code == 200:
                    osv_data = response.json()
                    vulns = osv_data.get('vulns', [])

                    for vuln in vulns:
                        finding = {
                            "type": "vulnerability",
                            "language": "nodejs",
                            "package": package['name'],
                            "version": package['version'],
                            "severity": "HIGH",  # OSV doesn't always provide severity
                            "description": vuln.get('summary', 'Vulnerability found'),
                            "vulnerability_id": vuln.get('id', 'UNKNOWN'),
                            "file": file_path
                        }
                        findings.append(finding)
                        logger.info(f"Found vulnerability: {package['name']} {package['version']} - {vuln.get('id')}")

            except Exception as e:
                logger.error(f"Error querying OSV for {package['name']}: {e}")
                continue

        logger.info(f"OSV scan found {len(findings)} Node.js vulnerabilities")

    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse package.json: {e}")

    return findings
