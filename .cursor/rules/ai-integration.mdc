---
description: "AI integration rules for Amazon Bedrock, prompt engineering, and AI-powered code review"
globs: ["**/ai_*.py", "**/bedrock*.py", "**/prompts/**/*"]
alwaysApply: false
---

# AI Integration with Amazon Bedrock

## Overview
AI-powered code review using Amazon Bedrock (Claude 3.5 Sonnet) is a core differentiator.

## Bedrock Configuration

### Model Selection
```python
# Always use this specific model
MODEL_ID = "anthropic.claude-3-5-sonnet-20240620-v1:0"
MODEL_KWARGS = {
    "max_tokens": 4096,
    "temperature": 0.3,  # Lower temperature for consistent code analysis
    "top_p": 0.9,
    "stop_sequences": []
}
```

### Client Setup
```python
import boto3
import json
from typing import Dict, List, Optional

class BedrockClient:
    """Wrapper for Amazon Bedrock interactions."""
    
    def __init__(self, region: str = "us-east-1"):
        self.client = boto3.client(
            service_name="bedrock-runtime",
            region_name=region
        )
        self.model_id = MODEL_ID
    
    def analyze_code(self, code: str, filename: str) -> Dict:
        """Analyze code for quality issues."""
        prompt = self._build_analysis_prompt(code, filename)
        
        try:
            response = self.client.invoke_model(
                modelId=self.model_id,
                contentType="application/json",
                accept="application/json",
                body=json.dumps({
                    "anthropic_version": "bedrock-2023-05-31",
                    "messages": [{
                        "role": "user",
                        "content": prompt
                    }],
                    **MODEL_KWARGS
                })
            )
            
            result = json.loads(response["body"].read())
            return self._parse_response(result)
            
        except Exception as e:
            logger.error(f"Bedrock invocation failed: {str(e)}")
            return {"findings": [], "error": str(e)}
```

## Error Handling
- Always implement retry logic with exponential backoff
- Have fallback strategies when Bedrock fails
- Validate all AI responses before using them
- Log all AI interactions for debugging

## Cost Optimization
- Truncate large files to manage token usage
- Batch small files together to reduce API calls
- Monitor token usage and implement limits
- Smart truncation - keep imports and function signatures

## Best Practices
1. **Prompt Clarity**: Be explicit about expected output format
2. **Context Limiting**: Focus on changed files only
3. **Error Recovery**: Always have fallback for when AI fails
4. **Response Validation**: Never trust AI output without validation
5. **Timeout Handling**: Set appropriate timeouts for Bedrock calls 