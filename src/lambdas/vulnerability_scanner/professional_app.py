#!/usr/bin/env python3
"""
DevSecOps Sentinel - Professional Multi-Source Vulnerability Scanner
Enterprise-grade vulnerability detection with comprehensive source orchestration
Author: Expert Security Engineering Team
Version: 4.0 - Professional Grade
"""

import asyncio
import concurrent.futures
import hashlib
import json
import logging
import os
import subprocess
import tempfile
import time
import zipfile
from dataclasses import dataclass, field
from enum import Enum
from typing import List, Dict, Any, Optional, Set, Tuple, Union
import shutil

import boto3
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# Professional PATH configuration
PROFESSIONAL_PATHS = ['/opt/bin', '/opt/tools', '/usr/local/bin', '/usr/bin', '/bin']
for path in PROFESSIONAL_PATHS:
    if path not in os.environ.get('PATH', ''):
        os.environ['PATH'] = f"{path}:{os.environ.get('PATH', '')}"

from sentinel_utils.utils import (
    get_github_token,
    create_session_with_retries,
    format_error_response,
    format_success_response,
    DEFAULT_TIMEOUT
)

# Professional logging configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
)
logger = logging.getLogger(__name__)

# AWS clients with professional configuration
secrets_manager = boto3.client("secretsmanager", region_name='us-east-1')

# Scanner identification
SCANNER_TYPE = "vulnerabilities"
SCANNER_VERSION = "4.0-PROFESSIONAL"

class SeverityLevel(Enum):
    """Professional severity classification."""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

class EcosystemType(Enum):
    """Supported package ecosystems."""
    PYTHON = "python"
    NODEJS = "nodejs"
    JAVA = "java"
    GO = "go"
    RUST = "rust"
    RUBY = "ruby"
    PHP = "php"
    DOTNET = "dotnet"

@dataclass
class VulnerabilityFinding:
    """Professional vulnerability finding data structure."""
    id: str = field(default_factory=lambda: hashlib.sha256(str(time.time()).encode()).hexdigest()[:16])
    source: str = ""
    ecosystem: EcosystemType = EcosystemType.PYTHON
    package_name: str = ""
    package_version: str = ""
    vulnerability_id: str = ""
    severity: SeverityLevel = SeverityLevel.INFO
    cvss_score: float = 0.0
    summary: str = ""
    description: str = ""
    fixed_version: str = ""
    file_path: str = ""
    confidence: float = 1.0
    published_date: str = ""
    modified_date: str = ""
    references: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)

class ProfessionalVulnerabilityOrchestrator:
    """
    Enterprise-grade vulnerability scanning orchestrator.
    Implements multi-source, multi-ecosystem detection with intelligent fusion.
    """
    
    def __init__(self):
        self.session = create_session_with_retries()
        self.github_token = get_github_token(secrets_manager)
        self.vulnerability_sources = self._initialize_professional_sources()
        self.scan_start_time = time.time()
        
        logger.info(f"🎯 Professional Vulnerability Scanner v{SCANNER_VERSION} initialized")
        logger.info(f"Available sources: {list(self.vulnerability_sources.keys())}")
    
    def _initialize_professional_sources(self) -> Dict[str, Dict[str, Any]]:
        """Initialize professional vulnerability data sources."""
        return {
            "osv_api": {
                "name": "Open Source Vulnerabilities",
                "endpoint": "https://api.osv.dev/v1/querybatch",
                "priority": 1,
                "confidence": 0.95,
                "ecosystems": ["python", "nodejs", "go", "rust", "java"]
            },
            "github_advisory": {
                "name": "GitHub Security Advisory",
                "endpoint": "https://api.github.com/advisories",
                "priority": 2,
                "confidence": 0.90,
                "ecosystems": ["python", "nodejs", "java", "ruby", "php"]
            },
            "nvd_api": {
                "name": "National Vulnerability Database",
                "endpoint": "https://services.nvd.nist.gov/rest/json/cves/2.0",
                "priority": 3,
                "confidence": 0.85,
                "ecosystems": ["all"]
            },
            "snyk_api": {
                "name": "Snyk Vulnerability Database",
                "endpoint": "https://snyk.io/api/v1/test",
                "priority": 4,
                "confidence": 0.80,
                "ecosystems": ["python", "nodejs", "java", "ruby", "php", "go"]
            }
        }
    
    def scan_comprehensive_vulnerabilities(self, repo_path: str) -> List[VulnerabilityFinding]:
        """
        Execute comprehensive multi-source vulnerability scanning.
        
        Args:
            repo_path: Path to repository for scanning
            
        Returns:
            List of professionally analyzed vulnerability findings
        """
        logger.info("🚀 Starting comprehensive professional vulnerability scan")
        
        all_findings = []
        
        # Discover all dependency files across ecosystems
        dependency_files = self._discover_all_dependencies(repo_path)
        logger.info(f"📋 Discovered dependencies: {dependency_files}")
        
        # Scan each ecosystem with multiple sources
        for ecosystem, files in dependency_files.items():
            if files:
                logger.info(f"🔍 Scanning {ecosystem} ecosystem...")
                ecosystem_findings = self._scan_ecosystem_comprehensive(ecosystem, files, repo_path)
                all_findings.extend(ecosystem_findings)
        
        # Professional fusion and deduplication
        final_findings = self._intelligent_vulnerability_fusion(all_findings)
        
        # Professional verification and scoring
        verified_findings = self._professional_vulnerability_verification(final_findings)
        
        scan_duration = time.time() - self.scan_start_time
        logger.info(f"🎯 Professional vulnerability scan completed in {scan_duration:.2f}s")
        logger.info(f"📊 Scan statistics:")
        logger.info(f"  - Total raw findings: {len(all_findings)}")
        logger.info(f"  - After intelligent fusion: {len(final_findings)}")
        logger.info(f"  - After verification: {len(verified_findings)}")
        
        return verified_findings
    
    def _discover_all_dependencies(self, repo_path: str) -> Dict[str, List[str]]:
        """Discover all dependency files across all supported ecosystems."""
        dependency_patterns = {
            EcosystemType.PYTHON: ["requirements.txt", "Pipfile", "pyproject.toml", "setup.py", "poetry.lock"],
            EcosystemType.NODEJS: ["package.json", "package-lock.json", "yarn.lock", "npm-shrinkwrap.json"],
            EcosystemType.JAVA: ["pom.xml", "build.gradle", "gradle.lockfile", "build.gradle.kts"],
            EcosystemType.GO: ["go.mod", "go.sum", "Gopkg.toml", "Gopkg.lock"],
            EcosystemType.RUST: ["Cargo.toml", "Cargo.lock"],
            EcosystemType.RUBY: ["Gemfile", "Gemfile.lock", "*.gemspec"],
            EcosystemType.PHP: ["composer.json", "composer.lock"],
            EcosystemType.DOTNET: ["*.csproj", "packages.config", "project.json"]
        }
        
        discovered = {ecosystem: [] for ecosystem in EcosystemType}
        
        for root, dirs, files in os.walk(repo_path):
            # Skip common non-source directories
            dirs[:] = [d for d in dirs if d not in {'.git', 'node_modules', '__pycache__', '.venv', 'venv', 'target', 'build', 'dist'}]
            
            for file in files:
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, repo_path)
                
                for ecosystem, patterns in dependency_patterns.items():
                    for pattern in patterns:
                        if self._matches_pattern(file, pattern):
                            discovered[ecosystem].append(relative_path)
                            break
        
        return {k.value: v for k, v in discovered.items() if v}
    
    def _matches_pattern(self, filename: str, pattern: str) -> bool:
        """Check if filename matches dependency pattern."""
        if '*' in pattern:
            import fnmatch
            return fnmatch.fnmatch(filename, pattern)
        return filename == pattern
    
    def _scan_ecosystem_comprehensive(self, ecosystem: str, files: List[str], repo_path: str) -> List[VulnerabilityFinding]:
        """Scan ecosystem using all available sources."""
        findings = []
        
        # Parse dependencies from all files
        all_dependencies = []
        for file_path in files:
            full_path = os.path.join(repo_path, file_path)
            deps = self._parse_dependencies_professional(ecosystem, full_path)
            all_dependencies.extend(deps)
        
        if not all_dependencies:
            return findings
        
        # Query all vulnerability sources
        for source_name, source_config in self.vulnerability_sources.items():
            if ecosystem in source_config["ecosystems"] or "all" in source_config["ecosystems"]:
                try:
                    source_findings = self._query_vulnerability_source(source_name, ecosystem, all_dependencies)
                    findings.extend(source_findings)
                    logger.info(f"🔍 {source_name} found {len(source_findings)} vulnerabilities for {ecosystem}")
                except Exception as e:
                    logger.error(f"❌ {source_name} query failed: {e}")
        
        return findings
    
    def _parse_dependencies_professional(self, ecosystem: str, file_path: str) -> List[Dict[str, str]]:
        """Professional dependency parsing for all ecosystems."""
        dependencies = []
        
        try:
            if ecosystem == "python":
                dependencies = self._parse_python_dependencies(file_path)
            elif ecosystem == "nodejs":
                dependencies = self._parse_nodejs_dependencies(file_path)
            elif ecosystem == "java":
                dependencies = self._parse_java_dependencies(file_path)
            elif ecosystem == "go":
                dependencies = self._parse_go_dependencies(file_path)
            elif ecosystem == "rust":
                dependencies = self._parse_rust_dependencies(file_path)
            elif ecosystem == "ruby":
                dependencies = self._parse_ruby_dependencies(file_path)
            elif ecosystem == "php":
                dependencies = self._parse_php_dependencies(file_path)
            elif ecosystem == "dotnet":
                dependencies = self._parse_dotnet_dependencies(file_path)
        except Exception as e:
            logger.warning(f"Failed to parse {file_path}: {e}")
        
        return dependencies
    
    def _parse_python_dependencies(self, file_path: str) -> List[Dict[str, str]]:
        """Parse Python dependencies."""
        dependencies = []
        
        if file_path.endswith("requirements.txt"):
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        # Parse package==version format
                        if '==' in line:
                            name, version = line.split('==', 1)
                            dependencies.append({"name": name.strip(), "version": version.strip()})
                        elif '>=' in line:
                            name, version = line.split('>=', 1)
                            dependencies.append({"name": name.strip(), "version": version.strip()})
                        else:
                            dependencies.append({"name": line.strip(), "version": "*"})
        
        elif file_path.endswith("package.json"):
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                try:
                    data = json.load(f)
                    for dep_type in ["dependencies", "devDependencies"]:
                        if dep_type in data:
                            for name, version in data[dep_type].items():
                                dependencies.append({"name": name, "version": version.lstrip('^~')})
                except json.JSONDecodeError:
                    pass
        
        return dependencies

def lambda_handler(event, context):
    """
    Professional Lambda handler with enterprise-grade error handling.
    
    Args:
        event: Lambda event containing repository details
        context: Lambda context
        
    Returns:
        Professional response with comprehensive vulnerability findings
    """
    logger.info(f"🎯 Professional Vulnerability Scanner v{SCANNER_VERSION} - Enterprise Grade - DEPLOYED 2025-06-28")
    
    try:
        # Extract repository details
        repo_details = event.get("repo_details", {})
        repo_full_name = repo_details.get("repository_full_name", "")
        zip_url = repo_details.get("zipball_url", "")
        
        if not zip_url:
            raise ValueError("Repository zipball URL not provided")
        
        logger.info(f"🔍 Scanning repository: {repo_full_name}")
        
        # Initialize professional orchestrator
        orchestrator = ProfessionalVulnerabilityOrchestrator()
        
        # Download and scan repository
        findings = orchestrator.scan_repository_professional(zip_url)
        
        # Convert findings to response format
        response_findings = []
        for finding in findings:
            response_findings.append({
                "package": finding.package_name,
                "version": finding.package_version,
                "vulnerability_id": finding.vulnerability_id,
                "severity": finding.severity.value,
                "summary": finding.summary,
                "fixed_version": finding.fixed_version,
                "file": finding.file_path,
                "source": finding.source,
                "confidence": finding.confidence
            })
        
        logger.info(f"✅ Professional vulnerability scan completed: {len(response_findings)} vulnerabilities found")
        
        return format_success_response(SCANNER_TYPE, response_findings)
        
    except Exception as e:
        logger.error(f"❌ Professional vulnerability scanner error: {str(e)}", exc_info=True)
        return format_error_response(SCANNER_TYPE, e)
